{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8151eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from train_model import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1036fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>...</th>\n",
       "      <th>Rolling_Return_30</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>Bollinger_Upper</th>\n",
       "      <th>Bollinger_Lower</th>\n",
       "      <th>Target_Close_Next_Day</th>\n",
       "      <th>Target_UpDown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-29</th>\n",
       "      <td>206.28</td>\n",
       "      <td>62308820.0</td>\n",
       "      <td>209.80</td>\n",
       "      <td>214.8900</td>\n",
       "      <td>205.97</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431667</td>\n",
       "      <td>214.864</td>\n",
       "      <td>211.270095</td>\n",
       "      <td>53.838631</td>\n",
       "      <td>-2.048580</td>\n",
       "      <td>-1.791235</td>\n",
       "      <td>226.838799</td>\n",
       "      <td>189.888201</td>\n",
       "      <td>214.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-30</th>\n",
       "      <td>214.11</td>\n",
       "      <td>63370610.0</td>\n",
       "      <td>208.63</td>\n",
       "      <td>214.5701</td>\n",
       "      <td>207.03</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.836333</td>\n",
       "      <td>214.663</td>\n",
       "      <td>211.786441</td>\n",
       "      <td>59.538567</td>\n",
       "      <td>-1.698727</td>\n",
       "      <td>-1.772734</td>\n",
       "      <td>227.333581</td>\n",
       "      <td>190.037419</td>\n",
       "      <td>210.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-03</th>\n",
       "      <td>210.60</td>\n",
       "      <td>76714220.0</td>\n",
       "      <td>215.26</td>\n",
       "      <td>219.9043</td>\n",
       "      <td>209.64</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.363667</td>\n",
       "      <td>213.451</td>\n",
       "      <td>211.570725</td>\n",
       "      <td>51.724997</td>\n",
       "      <td>-1.685267</td>\n",
       "      <td>-1.755240</td>\n",
       "      <td>227.350080</td>\n",
       "      <td>191.192920</td>\n",
       "      <td>219.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04</th>\n",
       "      <td>219.41</td>\n",
       "      <td>80651770.0</td>\n",
       "      <td>210.59</td>\n",
       "      <td>222.2200</td>\n",
       "      <td>210.57</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.899000</td>\n",
       "      <td>213.282</td>\n",
       "      <td>212.996048</td>\n",
       "      <td>60.907441</td>\n",
       "      <td>-0.952724</td>\n",
       "      <td>-1.594737</td>\n",
       "      <td>228.350604</td>\n",
       "      <td>192.069396</td>\n",
       "      <td>230.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-05</th>\n",
       "      <td>230.17</td>\n",
       "      <td>119355000.0</td>\n",
       "      <td>223.49</td>\n",
       "      <td>235.0000</td>\n",
       "      <td>222.25</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472667</td>\n",
       "      <td>213.972</td>\n",
       "      <td>216.118584</td>\n",
       "      <td>59.938004</td>\n",
       "      <td>0.490411</td>\n",
       "      <td>-1.177707</td>\n",
       "      <td>230.179380</td>\n",
       "      <td>194.081620</td>\n",
       "      <td>210.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close/Last       Volume    Open      High     Low  Year  Month  \\\n",
       "Date                                                                         \n",
       "2024-08-29      206.28   62308820.0  209.80  214.8900  205.97  2024      8   \n",
       "2024-08-30      214.11   63370610.0  208.63  214.5701  207.03  2024      8   \n",
       "2024-09-03      210.60   76714220.0  215.26  219.9043  209.64  2024      9   \n",
       "2024-09-04      219.41   80651770.0  210.59  222.2200  210.57  2024      9   \n",
       "2024-09-05      230.17  119355000.0  223.49  235.0000  222.25  2024      9   \n",
       "\n",
       "            Day  DayOfWeek  IsWeekend  ...  Rolling_Return_30   SMA_10  \\\n",
       "Date                                   ...                               \n",
       "2024-08-29   29          3          0  ...          -1.431667  214.864   \n",
       "2024-08-30   30          4          0  ...          -0.836333  214.663   \n",
       "2024-09-03    3          1          0  ...          -1.363667  213.451   \n",
       "2024-09-04    4          2          0  ...          -0.899000  213.282   \n",
       "2024-09-05    5          3          0  ...           0.472667  213.972   \n",
       "\n",
       "                EMA_10     RSI_14      MACD  MACD_Signal  Bollinger_Upper  \\\n",
       "Date                                                                        \n",
       "2024-08-29  211.270095  53.838631 -2.048580    -1.791235       226.838799   \n",
       "2024-08-30  211.786441  59.538567 -1.698727    -1.772734       227.333581   \n",
       "2024-09-03  211.570725  51.724997 -1.685267    -1.755240       227.350080   \n",
       "2024-09-04  212.996048  60.907441 -0.952724    -1.594737       228.350604   \n",
       "2024-09-05  216.118584  59.938004  0.490411    -1.177707       230.179380   \n",
       "\n",
       "            Bollinger_Lower  Target_Close_Next_Day  Target_UpDown  \n",
       "Date                                                               \n",
       "2024-08-29       189.888201                 214.11              1  \n",
       "2024-08-30       190.037419                 210.60              0  \n",
       "2024-09-03       191.192920                 219.41              1  \n",
       "2024-09-04       192.069396                 230.17              1  \n",
       "2024-09-05       194.081620                 210.73              0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../../data/processed/processed_stock_data.csv\"\n",
    "path = '../../data/interim/engineered_features.csv'\n",
    "df = pd.read_csv(path, parse_dates=[\"Date\"])\n",
    "\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "# df = df[[\"Close/Last\"]]  # Using only close prices for CNN input\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 221 entries, 2023-10-19 to 2024-09-05\n",
      "Data columns (total 59 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Close/Last                 221 non-null    float64\n",
      " 1   Volume                     221 non-null    float64\n",
      " 2   Open                       221 non-null    float64\n",
      " 3   High                       221 non-null    float64\n",
      " 4   Low                        221 non-null    float64\n",
      " 5   Year                       221 non-null    int64  \n",
      " 6   Month                      221 non-null    int64  \n",
      " 7   Day                        221 non-null    int64  \n",
      " 8   DayOfWeek                  221 non-null    int64  \n",
      " 9   IsWeekend                  221 non-null    int64  \n",
      " 10  Close/Last_lag_1           221 non-null    float64\n",
      " 11  Close/Last_lag_2           221 non-null    float64\n",
      " 12  Close/Last_lag_3           221 non-null    float64\n",
      " 13  Volume_lag_1               221 non-null    float64\n",
      " 14  Volume_lag_2               221 non-null    float64\n",
      " 15  Volume_lag_3               221 non-null    float64\n",
      " 16  Close/Last_roll_mean_7     221 non-null    float64\n",
      " 17  Close/Last_roll_median_7   221 non-null    float64\n",
      " 18  Close/Last_roll_std_7      221 non-null    float64\n",
      " 19  Close/Last_roll_max_7      221 non-null    float64\n",
      " 20  Close/Last_roll_min_7      221 non-null    float64\n",
      " 21  Close/Last_roll_mean_14    221 non-null    float64\n",
      " 22  Close/Last_roll_median_14  221 non-null    float64\n",
      " 23  Close/Last_roll_std_14     221 non-null    float64\n",
      " 24  Close/Last_roll_max_14     221 non-null    float64\n",
      " 25  Close/Last_roll_min_14     221 non-null    float64\n",
      " 26  Close/Last_roll_mean_30    221 non-null    float64\n",
      " 27  Close/Last_roll_median_30  221 non-null    float64\n",
      " 28  Close/Last_roll_std_30     221 non-null    float64\n",
      " 29  Close/Last_roll_max_30     221 non-null    float64\n",
      " 30  Close/Last_roll_min_30     221 non-null    float64\n",
      " 31  Volume_roll_mean_7         221 non-null    float64\n",
      " 32  Volume_roll_median_7       221 non-null    float64\n",
      " 33  Volume_roll_std_7          221 non-null    float64\n",
      " 34  Volume_roll_max_7          221 non-null    float64\n",
      " 35  Volume_roll_min_7          221 non-null    float64\n",
      " 36  Volume_roll_mean_14        221 non-null    float64\n",
      " 37  Volume_roll_median_14      221 non-null    float64\n",
      " 38  Volume_roll_std_14         221 non-null    float64\n",
      " 39  Volume_roll_max_14         221 non-null    float64\n",
      " 40  Volume_roll_min_14         221 non-null    float64\n",
      " 41  Volume_roll_mean_30        221 non-null    float64\n",
      " 42  Volume_roll_median_30      221 non-null    float64\n",
      " 43  Volume_roll_std_30         221 non-null    float64\n",
      " 44  Volume_roll_max_30         221 non-null    float64\n",
      " 45  Volume_roll_min_30         221 non-null    float64\n",
      " 46  Pct_Change                 221 non-null    float64\n",
      " 47  Daily_Return               221 non-null    float64\n",
      " 48  Rolling_Return_7           221 non-null    float64\n",
      " 49  Rolling_Return_30          221 non-null    float64\n",
      " 50  SMA_10                     221 non-null    float64\n",
      " 51  EMA_10                     221 non-null    float64\n",
      " 52  RSI_14                     221 non-null    float64\n",
      " 53  MACD                       221 non-null    float64\n",
      " 54  MACD_Signal                221 non-null    float64\n",
      " 55  Bollinger_Upper            221 non-null    float64\n",
      " 56  Bollinger_Lower            221 non-null    float64\n",
      " 57  Target_Close_Next_Day      221 non-null    float64\n",
      " 58  Target_UpDown              221 non-null    int64  \n",
      "dtypes: float64(53), int64(6)\n",
      "memory usage: 103.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a22b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Close/Last', 'Volume', 'Open', 'High', 'Low', 'Year', 'Month', 'Day',\n",
       "       'DayOfWeek', 'IsWeekend', 'Close/Last_lag_1', 'Close/Last_lag_2',\n",
       "       'Close/Last_lag_3', 'Volume_lag_1', 'Volume_lag_2', 'Volume_lag_3',\n",
       "       'Close/Last_roll_mean_7', 'Close/Last_roll_median_7',\n",
       "       'Close/Last_roll_std_7', 'Close/Last_roll_max_7',\n",
       "       'Close/Last_roll_min_7', 'Close/Last_roll_mean_14',\n",
       "       'Close/Last_roll_median_14', 'Close/Last_roll_std_14',\n",
       "       'Close/Last_roll_max_14', 'Close/Last_roll_min_14',\n",
       "       'Close/Last_roll_mean_30', 'Close/Last_roll_median_30',\n",
       "       'Close/Last_roll_std_30', 'Close/Last_roll_max_30',\n",
       "       'Close/Last_roll_min_30', 'Volume_roll_mean_7', 'Volume_roll_median_7',\n",
       "       'Volume_roll_std_7', 'Volume_roll_max_7', 'Volume_roll_min_7',\n",
       "       'Volume_roll_mean_14', 'Volume_roll_median_14', 'Volume_roll_std_14',\n",
       "       'Volume_roll_max_14', 'Volume_roll_min_14', 'Volume_roll_mean_30',\n",
       "       'Volume_roll_median_30', 'Volume_roll_std_30', 'Volume_roll_max_30',\n",
       "       'Volume_roll_min_30', 'Pct_Change', 'Daily_Return', 'Rolling_Return_7',\n",
       "       'Rolling_Return_30', 'SMA_10', 'EMA_10', 'RSI_14', 'MACD',\n",
       "       'MACD_Signal', 'Bollinger_Upper', 'Bollinger_Lower',\n",
       "       'Target_Close_Next_Day', 'Target_UpDown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2a6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"Close/Last\", 'Target_Close_Next_Day', 'Daily_Return', 'SMA_10', 'EMA_10', 'RSI_14', 'MACD', 'Bollinger_Upper']\n",
    "target_col = \"Target_Close_Next_Day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd82ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['cnn', 'lstm', 'hybrid']\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efc688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3x\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1291 - mae: 0.3022 - val_loss: 0.3504 - val_mae: 0.5884\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0246 - mae: 0.1348 - val_loss: 0.2096 - val_mae: 0.4537\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - mae: 0.0747 - val_loss: 0.0705 - val_mae: 0.2590\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0073 - mae: 0.0667 - val_loss: 0.1843 - val_mae: 0.4247\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0552 - val_loss: 0.1589 - val_mae: 0.3936\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0465 - val_loss: 0.1472 - val_mae: 0.3784\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.1538 - val_mae: 0.3869\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.1236 - val_mae: 0.3457\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0496 - val_loss: 0.1477 - val_mae: 0.3788\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0447 - val_loss: 0.1406 - val_mae: 0.3694\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.1240 - val_mae: 0.3462\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0362 - val_loss: 0.1508 - val_mae: 0.3828\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0372 - val_loss: 0.1301 - val_mae: 0.3549\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.1267 - val_mae: 0.3499\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0428 - val_loss: 0.1352 - val_mae: 0.3617\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.1087 - val_mae: 0.3231\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0355 - val_loss: 0.1302 - val_mae: 0.3546\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0329 - val_loss: 0.1151 - val_mae: 0.3328\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0297 - val_loss: 0.1316 - val_mae: 0.3564\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.1121 - val_mae: 0.3281\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0275 - val_loss: 0.1437 - val_mae: 0.3725\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 0.1203 - val_mae: 0.3396\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9202e-04 - mae: 0.0222 - val_loss: 0.1301 - val_mae: 0.3534\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0298 - val_loss: 0.1118 - val_mae: 0.3267\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3797e-04 - mae: 0.0236 - val_loss: 0.1134 - val_mae: 0.3290\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0266 - val_loss: 0.1162 - val_mae: 0.3326\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 0.1184 - val_mae: 0.3358\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1223e-04 - mae: 0.0243 - val_loss: 0.1226 - val_mae: 0.3416\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0270 - val_loss: 0.1163 - val_mae: 0.3321\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7072e-04 - mae: 0.0251 - val_loss: 0.1166 - val_mae: 0.3326\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9977e-04 - mae: 0.0235 - val_loss: 0.1376 - val_mae: 0.3625\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.1113 - val_mae: 0.3238\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0156e-04 - mae: 0.0222 - val_loss: 0.1175 - val_mae: 0.3328\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0264 - val_loss: 0.1170 - val_mae: 0.3322\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0358e-04 - mae: 0.0226 - val_loss: 0.1124 - val_mae: 0.3252\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7817e-04 - mae: 0.0211 - val_loss: 0.1276 - val_mae: 0.3476\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7311e-04 - mae: 0.0204 - val_loss: 0.1115 - val_mae: 0.3241\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3265e-04 - mae: 0.0229 - val_loss: 0.1232 - val_mae: 0.3416\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2964e-04 - mae: 0.0199 - val_loss: 0.1152 - val_mae: 0.3296\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5360e-04 - mae: 0.0203 - val_loss: 0.1127 - val_mae: 0.3257\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9227e-04 - mae: 0.0179 - val_loss: 0.1192 - val_mae: 0.3348\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1029e-04 - mae: 0.0196 - val_loss: 0.1090 - val_mae: 0.3185\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7271e-04 - mae: 0.0236 - val_loss: 0.1145 - val_mae: 0.3267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3x\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.1907 - val_loss: 0.6051\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0538 - val_loss: 0.2074\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0389 - val_loss: 0.1867\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0226 - val_loss: 0.2962\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0106 - val_loss: 0.3392\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0111 - val_loss: 0.2777\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - val_loss: 0.2000\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.1779\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.2123\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0064 - val_loss: 0.2397\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - val_loss: 0.1980\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - val_loss: 0.1598\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.1601\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - val_loss: 0.1548\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.1573\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - val_loss: 0.1576\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - val_loss: 0.1461\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0040 - val_loss: 0.1332\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.1403\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.1244\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.1033\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.1011\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - val_loss: 0.1198\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0030 - val_loss: 0.1246\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0929\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0848\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 0.1028\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 0.1051\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 0.0793\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0766\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0838\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0031 - val_loss: 0.0737\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0025 - val_loss: 0.0750\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0026 - val_loss: 0.0754\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0546\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0561\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 0.0698\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0576\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 0.0503\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0571\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 0.0466\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0021 - val_loss: 0.0569\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 0.0585\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.0437\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 0.0542\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 0.0400\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0514\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0425\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0368\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0583\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0030 - val_loss: 0.0369\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0385\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 0.0518\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0308\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0383\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0364\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0313\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0285\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0306\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0303\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 0.0258\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0297\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0236\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0253\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0329\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0199\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0299\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0239\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0224\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 0.0259\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 0.0204\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0247\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - val_loss: 0.0233\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0142\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0313\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0226\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0017 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0325\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0191\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.5169e-04 - val_loss: 0.0222\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0268\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0184\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0145\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0215\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0112\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0184\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0169\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.8058e-04 - val_loss: 0.0146\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0162\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0106\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0137\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.3625e-04 - val_loss: 0.0110\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.9429e-04 - val_loss: 0.0105\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.6618e-04 - val_loss: 0.0113\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.2694e-04 - val_loss: 0.0077\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\n",
      "Training HYBRID model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3x\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0357 - val_loss: 0.1861\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - val_loss: 0.2718\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0071 - val_loss: 0.1335\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0117 - val_loss: 0.2059\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - val_loss: 0.2139\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - val_loss: 0.1397\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0050 - val_loss: 0.1298\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - val_loss: 0.1269\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0038 - val_loss: 0.1012\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.0830\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0749\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0032 - val_loss: 0.0951\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0032 - val_loss: 0.0716\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0027 - val_loss: 0.0536\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0950\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0556\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0029 - val_loss: 0.0673\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 0.0863\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0030 - val_loss: 0.0565\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0676\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0018 - val_loss: 0.0841\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0584\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0659\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0646\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0535\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0515\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0025 - val_loss: 0.0544\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0496\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0438\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0024 - val_loss: 0.0524\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0468\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0505\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0406\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0016 - val_loss: 0.0525\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0415\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 0.0434\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0017 - val_loss: 0.0362\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0021 - val_loss: 0.0478\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0014 - val_loss: 0.0363\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0471\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0428\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0378\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0348\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0341\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0500\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0340\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0518\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0381\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0572\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0343\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0017 - val_loss: 0.0518\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0016 - val_loss: 0.0503\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0429\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0679\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0455\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0015 - val_loss: 0.0679\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0017 - val_loss: 0.0483\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0626\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0648\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0458\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0602\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0364\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0462\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0011 - val_loss: 0.0443\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0469\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0417\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0471\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0386\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0570\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0481\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0545\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0014 - val_loss: 0.0539\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0548\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0415\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0449\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0490\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0580\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0490\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.8962e-04 - val_loss: 0.0474\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0514\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 8.7795e-04 - val_loss: 0.0435\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0553\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 7.8497e-04 - val_loss: 0.0421\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0488\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0016 - val_loss: 0.0414\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0473\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000218D14828B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 198ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000218D14828B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "---->>\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(f\"\\nTraining {model_name.upper()} model...\")\n",
    "    trainer = ModelTrainer(\n",
    "        model_name=model_name,\n",
    "        feature_cols=feature_cols,\n",
    "        target_col=target_col,\n",
    "        test_size=0.2,\n",
    "        val_size=0.1\n",
    "    )\n",
    "    model_results = trainer.train_and_evaluate(df)\n",
    "    model_results[\"Model\"] = model_name.upper()\n",
    "    results.append(model_results)\n",
    "print('---->>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d9ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.854638</td>\n",
       "      <td>13.942570</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.481541</td>\n",
       "      <td>7.019525</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.339890</td>\n",
       "      <td>7.221533</td>\n",
       "      <td>HYBRID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE       RMSE   Model\n",
       "0  10.854638  13.942570     CNN\n",
       "1   6.481541   7.019525    LSTM\n",
       "2   5.339890   7.221533  HYBRID"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "# print(results_df.info())\n",
    "\n",
    "# Save results\n",
    "# results_df.to_csv(\"results/model_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e04989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.bar(results_df[\"Model\"], results_df[\"RMSE\"])\n",
    "plt.title(\"Model Comparison - RMSE\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.bar(results_df[\"Model\"], results_df[\"MAE\"])\n",
    "plt.title(\"Model Comparison - MAE Score\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9584da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
