
## Project Progress Overview: BullBearAI

This project is designed to predict stock market trends using traditional ML, deep learning, and a hybrid LSTM-CNN architecture. Below is the step-by-step progress with brief descriptions.

### Project Structure

```
BullBearAI/
â”‚
â”œâ”€â”€ data/                        # Raw and processed stock data
â”‚   â”œâ”€â”€ raw/                     # Untouched downloaded data
â”‚   â”œâ”€â”€ interim/                 # Intermediate transformation outputs
â”‚   â””â”€â”€ processed/               # Cleaned and final datasets
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for EDA, modeling, evaluation
â”‚   â”œâ”€â”€ 01_eda.ipynb                        # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb        # Feature engineering techniques
â”‚   â”œâ”€â”€ 03_ml_baselines.ipynb               # Traditional ML models: SVM, RF, LR, Gradient Boosting
â”‚   â”œâ”€â”€ 04_time_series_models.ipynb         # Time series statistical models: ARIMA, SARIMA, GARCH, etc.
â”‚   â”œâ”€â”€ 05_cnn_model.ipynb                  # CNN-based deep learning model
â”‚   â”œâ”€â”€ 06_lstm_model.ipynb                 # LSTM (RNN) based sequence model
â”‚   â”œâ”€â”€ 07_hybrid_cnn_lstm_model.ipynb      # Hybrid CNN-LSTM deep model
â”‚   â””â”€â”€ 08_model_comparison.ipynb           # Evaluation & performance comparison
â”‚
â”œâ”€â”€ src/                        # All source code
â”‚   â”œâ”€â”€ config/                 # Configuration files and parameters
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ data_loader/            # Data loading and preprocessing scripts
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features/               # Feature engineering functions
â”‚   â”‚   â””â”€â”€ technical_indicators.py
â”‚   â”œâ”€â”€ models/                 # ML & DL model definitions
â”‚   â”‚   â”œâ”€â”€ arima_model.py
â”‚   â”‚   â”œâ”€â”€ svm_model.py
â”‚   â”‚   â”œâ”€â”€ cnn_model.py
â”‚   â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”‚   â””â”€â”€ hybrid_model.py
â”‚   â”œâ”€â”€ training/               # Training and validation loops
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluation/             # Metrics and model comparisons
â”‚   â”‚   â””â”€â”€ evaluate.py
â”‚   â””â”€â”€ visualization/          # Custom plotting functions
â”‚       â””â”€â”€ plot_utils.py
â”‚
â”œâ”€â”€ saved_models/               # Checkpoints and final models (.h5 or .pth)
â”‚
â”œâ”€â”€ reports/                    # Analysis reports, result plots, performance graphs
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ model_comparison.md
â”‚
â”œâ”€â”€ cli/                        # Command-line tools for automation
â”‚   â””â”€â”€ run_train.py
â”‚
â”œâ”€â”€ tests/                      # Unit tests for various components
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_utils.py
â”‚   â””â”€â”€ test_data_loader.py
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Project overview, setup, and usage
â”œâ”€â”€ LICENSE                     # License info
â””â”€â”€ .gitignore                  # Files to ignore in version control
```


### Data Loading & Initial Inspection
- Loaded the raw stock market data (Netflix stock) from the `data/raw/` directory.
- Verified file integrity, parsed dates correctly, and ensured data types were appropriate.
- Saved a clean version in `data/processed/netflix_cleaned.csv`.

---

### Data Cleaning
- Removed duplicates and handled any missing/null values.
- Renamed columns for consistency and usability (`Close/Last` instead of `Close*`).
- Converted all date fields to `datetime` format.
- Ensured data is sorted chronologically.
- Exported cleaned dataset to `data/processed/`.

---

### Exploratory Data Analysis (EDA)
- Visualized time-series trends of `Close`, `Volume`, and `Open`.
- Used Seaborn and Matplotlib for:
  - Moving averages
  - Seasonal decomposition
  - Daily/Monthly return distributions
- Checked for trends, volatility, and patterns.
- Identified data gaps, outliers, or anomalies.
- All EDA work is saved in `notebooks/01_eda.ipynb`.

---

### Feature Engineering
Performed a comprehensive set of transformations to prepare predictive features:

#### Date-Based Features
- Extracted: `Year`, `Month`, `Day`, `DayOfWeek`, and `IsWeekend`.

#### Lag Features
- Created lagged versions of `Close/Last` and `Volume` (lags: 1, 2, 3 days).

#### Rolling Statistics
- Computed rolling means, medians, stds, max, min for 7, 14, and 30-day windows.

#### Volatility Measures
- Daily percentage change, return, and rolling return metrics.

#### Technical Indicators
- Simple & Exponential Moving Averages (SMA, EMA)
- RSI (Relative Strength Index)
- MACD (Moving Average Convergence Divergence)
- Bollinger Bands

#### Target Variable
- `Target_Close_Next_Day`: Next dayâ€™s close price
- `Target_UpDown`: Binary classification target (1 = price goes up, 0 = down)

ğŸ“ Engineered dataset saved to: `data/interim/engineered_features.csv`.

---

### Machine Learning Baseline Models (Regression)

This notebook builds baseline **regression models** to predict:

- **`Target_Close_Next_Day`** â€” the actual next-day closing price of the stock.

**Implemented Models**:
- Linear Regression  
- Support Vector Regression (SVR)  
- Random Forest Regressor  
- Gradient Boosting Regressor  

**Highlights**:
- Models trained on engineered features including lag features, rolling window stats, and technical indicators (e.g., RSI, MACD, Bollinger Bands).
- Evaluation metrics include:
  - MAE (Mean Absolute Error)
  - RMSE (Root Mean Squared Error)
  - RÂ² Score
- **Visualizations**:
  - Actual vs Predicted Prices (line plot)
  - Residual Plot (errors)
  - MAE & RMSE comparison bar charts

---

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange?logo=jupyter)
![License](https://img.shields.io/github/license/your-username/BullBearAI)
![Status](https://img.shields.io/badge/Progress-Phase%201%20âœ…-green)
